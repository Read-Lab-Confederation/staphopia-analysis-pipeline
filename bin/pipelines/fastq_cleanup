#! /usr/bin/env python
""" Clean up an input FASTQ file. """
import sys

from ruffus import *

from staphopia.helpers.time_job import time_job
from staphopia.tasks import fastq, shared

parser = cmdline.get_argparse(description='Cleanup FASTQ files')
parser.add_argument("-f", "--fastq", dest="fastq", required=True,
                    help="Compressed FASTQ file (*.tar.gz)",)
parser.add_argument('--log_times', action='store_true', default=False,
                    help='Write task run times to file (Default: STDERR).', )
options = parser.parse_args()

TIME_LOG = 'logs/fastq_cleanup.time' if options.log_times else sys.stderr
# Pipeline --------------------------------------------------------------------


@active_if(options.log_times)
def create_dir():
    """ Make logs directory if required. """
    out, err = shared.run_command(['mkdir', 'logs'])


@transform(options.fastq, regex(r"(.*).fastq.gz"), r"\1.original.fastq.stats")
@time_job(TIME_LOG, new_stream=True)
def raw_stats(input_file, output_file):
    """ Calculate sequence stats of the input FASTQ. """
    fastq.stats(input_file, output_file)


@follows(raw_stats)
@transform(options.fastq, regex(r"(.*).fastq.gz"),
           r"\1.cleanup.fastq.gz", r"\1.original.fastq.stats")
@time_job(TIME_LOG)
def cleanup(input_file, output_file, stats_file):
    """ Clean up FASTQ based on statistics. """
    fastq.cleanup(input_file, stats_file, output_file)


@follows(cleanup)
@transform(cleanup, regex(r"(.*).gz"), r"\1.stats", r"\1.db")
@time_job(TIME_LOG)
def cleanup_stats(input_file, output_file, db_file):
    """ Calculate sequence stats of the cleaned up FASTQ. """
    fastq.stats(input_file, output_file)


# -----------------------------------------------------------------------------
pipeline_run(exceptions_terminate_immediately=True, verbose=5)
